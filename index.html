<!DOCTYPE html>
<html lang="en">

<head>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600,300" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="./web/reset.css">
    <link rel="stylesheet" href="./web/index.css">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Debunked!</title>
</head>

<body>
    <header>
        <h1>Debunked! Analyzing the LOCO Conspiracy Corpus</h1>
        <span>By: <a href="https://www.logan-cooper.com/" target="_blank">Logan Cooper</a>, Dhyay Bhatt, Naman Parikh,
            Kushagra Ghosh
        </span>
    </header>
    <main>
        <h2>Part One: Tom</h2>
        <p>
            The time is May 2020.
            The COVID-19 pandemic has shut down much of public life across the world.
            The death toll in the United States alone is set to surpass 100,000.
            However, there is a bright spot in all of this: there is promising news out of Germany and the United
            Kingdom about two revolutionary vaccines against this novel disease.
            The mass production and distribution of those vaccines is still six months away though.
            In the mean time, large numbers of people are convinced that COVID is not as dangerous as it seems.
        </p>
        <p>
            We will center our story on one of these people.
            His name is Tom.
            In the midst of all of this chaos, he is stuck at home with nothing but time on his hands.
            He has been spending a lot of this time on the internet, finding articles to reinforce his notion that
            COVID-19 is less dangerous than we are being led to believe.
            This leads to him not taking precautions: gathering indoors with his friends, not wearing a mask, and
            preemptively announcing that he will not be getting vaccinated.
            When his friends and family try to bring him around, he counters with the articles he's been reading.
            And as he becomes more alienated from his friends and family, he starts to go deeper into his articles.
        </p>
        <p>
            The thing is, these articles don't end with "COVID is overblown."
            No, that is just where they start.
            Those articles lead Tom to more articles.
            "COVID is overblown" leads into "The vaccine is full of microchips."
            Who is putting these microchips in the vaccine?
            The Illuminati are.
            Why?
            To usher in the New World Order.
            How can we stop that?
            We can show up at the Capitol on January 6th to Stop the Steal!
        </p>

        <h2>Part Two: The Rabbit Hole</h2>
        <p>
            This story is, of course, a fiction, but it contains a grain of truth.
            There is no shortage of <a
                target="_blank"="https://misinforeview.hks.harvard.edu/article/why-do-people-believe-covid-19-conspiracy-theories/">academic
                research</a>, <a
                target="_blank"="https://fivethirtyeight.com/features/why-people-fall-for-conspiracy-theories/">news</a>,
            and <a target="_blank"="https://www.reddit.com/r/QAnonCasualties/">popular discourse</a> illustrating how
            people fall down this rabbit hole.
            However, not everyone takes this same path.
            Some people might start being skeptical of "Big Pharma" and find their way to Flat Earth.
            Others might have doubts about Princess Diana's death and end up thinking that the government is hiding
            evidence of alien life.
            How then might we map these relationships between common concepts in the world of conspiracy theories?
        </p>
        <p>
            One way to map this has emerged in the LOCO corpus.
            This is a 88-million-word corpus compiled by <a href="https://pubmed.ncbi.nlm.nih.gov/34697754/"
                target="_blank">Miani et al.</a> and released in 2021.
            By bringing together the text of thousands of articles about hundreds of topics, it enables us to use modern
            techniques in text analysis and natural language processing to study the relationships between these topics.
        </p>
        <p>
            If each of the 'paths' that someone can take from conspiracy to conspiracy is a rabbit hole, then we suppose
            our goal is to map the whole warren.
            Unlike young rabbits though, we are not going in blind: we have generated a set of hypotheses about how
            these conspiracies will be linked.
            These hypotheses come from our groups' long-standing interest in the world of conspiracy theories.
        </p>
        <p>
            In short, we hypothesize the following:
        <ul>
            <li>Conspiracy theories will 'cluster' together around certain topics, for example public health, political
                figures, or phenomena like UFO sightings.</li>
            <li>These clusters will be linked together by a few 'hub' conspiracies which easily tie into many others:
                things or people like the New World Order, George Soros, or COVID.</li>
            <li>Most of these articles will display negative sentiment, e.g. anger or fear.</li>
        </ul>
        </p>

        <h2>Part Three: Topic Modelling</h2>
        <div class="iframe-wrapper">
            <iframe id="topic-map" src="./web/intertopic_distance_map.html" frameborder="0"></iframe>
        </div>

        <h2>Part Four: Sentiment Analysis</h2>

        <h2>Part Five: Keyword Extraction</h2>
        <p>
            Starting with the search terms that Miani et al. used to compile LOCO, we put together a list of 127
            keywords that captured a number of topics in the conspiracy world.
            We then used these as so-called "candidate keywords" which we passed to the <a
                href="https://maartengr.github.io/KeyBERT/index.html" target="_blank">KeyBERT</a> algorithm.
            In short, KeyBERT uses a large language model to generate word embeddings -- context-aware numerical
            representations of words -- and then compares those to the list of candidate keywords.
            If the meaning of the article is close to any of the keywords, then it marks the article as containing that
            keyword.
        </p>
        <p>
            How does this help us map these theories?
            With the addition of another algorithm, or rather class of algorithms, called pattern mining.
            Pattern mining is how sites like Amazon know what to recommend you buy with the items in your cart: by
            looking at thousands of carts, they might notice the pattern that most people who buy a phone charger put an
            extra cable in there.
            We use that same approach here, but with articles instead of shopping carts, and keywords instead of items.
        </p>
        <div class="iframe-wrapper">
            <iframe id="conspiracy-map" src="./web/conspiracy_map.html" frameborder="0"></iframe>
        </div>


    </main>

</body>

</html>